{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Libraries"},{"metadata":{"execution":{"iopub.execute_input":"2021-02-28T00:06:01.015153Z","iopub.status.busy":"2021-02-28T00:06:01.014425Z","iopub.status.idle":"2021-02-28T00:06:03.319079Z","shell.execute_reply":"2021-02-28T00:06:03.318391Z"},"papermill":{"duration":2.343058,"end_time":"2021-02-28T00:06:03.31922","exception":false,"start_time":"2021-02-28T00:06:00.976162","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\npd.set_option('display.max_columns', 100)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom itertools import combinations","execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Read data and perform basic preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_data(DATA_DIR):\n    \n    train = pd.read_csv(DATA_DIR+\"train_Df64byy.csv\")\n    test = pd.read_csv(DATA_DIR+\"test_YCcRUnU.csv\")\n    \n    \n    #Removes train rows which has Region_Code not present in test set\n    test_region_list=test['Region_Code'].tolist()\n    train=train[train['Region_Code'].isin(test_region_list)]\n    \n    train['train_or_test']='train'\n    test['train_or_test']='test'\n    df=pd.concat([train,test])\n    \n    df['Holding_Policy_Duration']=(df['Holding_Policy_Duration'].replace(['14+'],[15])).astype(float)\n    \n    df['Holding_Policy_Duration'].fillna(-999,inplace=True)\n    df['Holding_Policy_Type'].fillna(-999,inplace=True)\n    \n    le = LabelEncoder()\n    for col in ['City_Code','Accomodation_Type','Reco_Insurance_Type','Health Indicator','Is_Spouse']:\n        df[col]=  df[col].astype('str')\n        df[col]= le.fit_transform(df[col])\n        \n\n    \n    return train,test,df","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def frequency_encoding(column_name,output_column_name,df):\n    fe_pol = (df.groupby(column_name).size()) / len(df)\n    df[output_column_name] = df[column_name].apply(lambda x : fe_pol[x])\n\ndef feature_engineering(df):\n    cat_features=[]\n    \n    #Interaction Feature (Combining 2 categorical features and performing frequency encoding)\n    \n    columns=['City_Code','Accomodation_Type','Reco_Insurance_Type','Health Indicator',\n             'Is_Spouse','Region_Code','Holding_Policy_Type','Reco_Policy_Cat']\n\n    comb = combinations(columns, 2) \n\n    for i in list(comb):  \n        df[f'{i[0]}_{i[1]}']=df[i[0]].astype(str)+'_'+df[i[1]].astype(str)\n        frequency_encoding(f'{i[0]}_{i[1]}',f'{i[0]}_{i[1]}',df)\n        cat_features.append(f'{i[0]}_{i[1]}')\n    \n    #Frequency Encoding\n    \n    frequency_encoding('City_Code','City_Code_fe',df)\n    frequency_encoding('Region_Code','Region_Code_fe',df)\n    frequency_encoding('Holding_Policy_Duration','Holding_Policy_Duration',df)\n    frequency_encoding('Holding_Policy_Type','Holding_Policy_Type_fe',df)\n    \n    #Deriving characteristics of each city by creating aggregate features\n    \n    city_aggregate_features = df.groupby(['City_Code']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'], \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'Holding_Policy_Type': ['nunique','count'] ,\n                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n                                                     })\n    city_aggregate_features.columns = ['city_aggregate_features' + '_'.join(c).strip('_') for c in city_aggregate_features.columns]\n    df = pd.merge(df, city_aggregate_features, on = ['City_Code'], how='left')\n\n    \n    city_region_aggregate_features = df.groupby(['City_Code','Region_Code']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'],  \n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'Holding_Policy_Type': ['nunique','count'] ,\n                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n                                                     })\n    city_region_aggregate_features.columns = ['city_region_aggregate_features' + '_'.join(c).strip('_') for c in city_region_aggregate_features.columns]\n    df = pd.merge(df, city_region_aggregate_features, on = ['City_Code','Region_Code'], how='left')\n\n    \n    city_recopolicycat_aggregate_features = df.groupby(['City_Code','Reco_Policy_Cat']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'], \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'Holding_Policy_Type': ['nunique','count'] \n                                                     })\n    city_recopolicycat_aggregate_features.columns = ['city_recopolicycat_aggregate_features' + '_'.join(c).strip('_') for c in city_recopolicycat_aggregate_features.columns]\n    df = pd.merge(df, city_recopolicycat_aggregate_features, on = ['City_Code','Reco_Policy_Cat'], how='left')\n    \n    \n    city_regioncoderecopolicycat_aggregate_features = df.groupby(['City_Code','Region_Code_Reco_Policy_Cat']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'], \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'Holding_Policy_Type': ['nunique','count'] ,\n                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n                                                     })\n\n    city_regioncoderecopolicycat_aggregate_features.columns = ['city_regioncoderecopolicycat_aggregate_features' + '_'.join(c).strip('_') for c in city_regioncoderecopolicycat_aggregate_features.columns]\n    df = pd.merge(df, city_regioncoderecopolicycat_aggregate_features, on = ['City_Code','Region_Code_Reco_Policy_Cat'], how='left')\n    \n    for i in cat_features:\n        df[f'city_{i}_max']=df.groupby('City_Code')[i].transform('max')\n        df[f'city_{i}_min']=df.groupby('City_Code')[i].transform('min')\n        df[f'city_{i}_mean']=df.groupby('City_Code')[i].transform('mean')\n        df[f'city_{i}_std']=df.groupby('City_Code')[i].transform('std')\n\n    \n        df[f'city_region_{i}_max']=df.groupby(['City_Code','Region_Code'])[i].transform('max')\n        df[f'city_region_{i}_min']=df.groupby(['City_Code','Region_Code'])[i].transform('min')\n        df[f'city_region_{i}_mean']=df.groupby(['City_Code','Region_Code'])[i].transform('mean')\n        df[f'city_region_{i}_std']=df.groupby(['City_Code','Region_Code'])[i].transform('std')\n\n    \n        df[f'city_recopolicycat_{i}_max']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('max')\n        df[f'city_recopolicycat_{i}_min']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('min')\n        df[f'city_recopolicycat_{i}_mean']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('mean')\n        df[f'city_recopolicycat_{i}_std']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('std')\n        \n        \n    \n    #Creating Age Bins and deriving characteristics of each age group by creating aggregate features\n    \n    Lower_Age_Bins = KBinsDiscretizer(n_bins=14, encode='ordinal', strategy='quantile')\n    df['Lower_Age_Bins'] =Lower_Age_Bins.fit_transform(df['Lower_Age'].values.reshape(-1,1)).astype(int)\n    \n    age_aggregate_features = df.groupby(['Lower_Age_Bins']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'], \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'Holding_Policy_Type': ['nunique','count'] ,\n                                                     'City_Code': ['nunique','count'] ,\n                                                     })\n    age_aggregate_features.columns = ['age_aggregate_features' + '_'.join(c).strip('_') for c in age_aggregate_features.columns]\n    df = pd.merge(df, age_aggregate_features, on = ['Lower_Age_Bins'], how='left')\n\n \n    #Deriving characteristics of Holding_Policy_Type by creating aggregate features\n    \n    holdingpolicytype_aggregate_features = df.groupby(['Holding_Policy_Type']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'], \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'City_Code': ['nunique','count'] ,\n                                                     })\n    holdingpolicytype_aggregate_features.columns = ['holdingpolicytype_aggregate_features' + '_'.join(c).strip('_') for c in holdingpolicytype_aggregate_features.columns]\n    df = pd.merge(df, holdingpolicytype_aggregate_features, on = ['Holding_Policy_Type'], how='left')\n    \n    #Deriving characteristics of Health Indicator by creating aggregate features\n    \n    Health_Indicator_aggregate_features = df.groupby(['Health Indicator']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'],  \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Holding_Policy_Type': ['nunique','count'] ,\n                                                     'City_Code': ['nunique','count'] ,\n                                                     })\n    Health_Indicator_aggregate_features.columns = ['Health_Indicator_aggregate_features' + '_'.join(c).strip('_') for c in Health_Indicator_aggregate_features.columns]\n    df = pd.merge(df, Health_Indicator_aggregate_features, on = ['Health Indicator'], how='left')\n    \n\n    #Deriving characteristics of Interaction_features by creating aggregate features (These interaction feature are selected for aggregating based on its feature importance)\n    \n    Region_CodeReco_Policy_Cat_grpd = df.groupby(['Region_Code_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n                                                     \n    Region_CodeReco_Policy_Cat_grpd.columns = ['grpd_by_Region_Code_Reco_Policy_Cat_' + '_'.join(c).strip('_') for c in Region_CodeReco_Policy_Cat_grpd.columns]\n    df = pd.merge(df, Region_CodeReco_Policy_Cat_grpd, on = ['Region_Code_Reco_Policy_Cat'], how='left')\n\n\n    City_CodeRegion_Code_grpd = df.groupby(['City_Code_Region_Code']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n                                                     \n    City_CodeRegion_Code_grpd.columns = ['grpd_by_City_CodeRegion_Code_' + '_'.join(c).strip('_') for c in City_CodeRegion_Code_grpd.columns]\n    df = pd.merge(df, City_CodeRegion_Code_grpd, on = ['City_Code_Region_Code'], how='left')\n\n\n    City_CodeReco_Policy_Cat_grpd = df.groupby(['City_Code_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n                                                     \n    City_CodeReco_Policy_Cat_grpd.columns = ['grpd_by_City_CodeReco_Policy_Cat_' + '_'.join(c).strip('_') for c in City_CodeReco_Policy_Cat_grpd.columns]\n    df = pd.merge(df, City_CodeReco_Policy_Cat_grpd, on = ['City_Code_Reco_Policy_Cat'], how='left')\n\n\n    Holding_Policy_TypeReco_Policy_Cat_grpd = df.groupby(['Holding_Policy_Type_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n                                                     \n    Holding_Policy_TypeReco_Policy_Cat_grpd.columns = ['grpd_by_Holding_Policy_TypeReco_Policy_Cat_' + '_'.join(c).strip('_') for c in Holding_Policy_TypeReco_Policy_Cat_grpd.columns]\n    df = pd.merge(df, Holding_Policy_TypeReco_Policy_Cat_grpd, on = ['Holding_Policy_Type_Reco_Policy_Cat'], how='left')\n    \n    return df,cat_features\n    ","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove unnecessary columns and prepare the train and test data for training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preparedatafortraining(df,train,test):\n    \n    train=df.loc[df.train_or_test.isin(['train'])]\n    test=df.loc[df.train_or_test.isin(['test'])]\n    \n    drop_columns={'ID','Response','Upper_Age','Lower_Age_Bins','train_or_test'}\n    \n    target=['Response']\n    \n    x=train.drop(columns=drop_columns,axis=1)\n    y=train[target]\n    x_test=test.drop(columns=drop_columns,axis=1)\n    \n    print(x.shape)\n    \n    return x,y,x_test","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def savedata(**DATA_DIR):\n    \n    train,test,df=process_data(\"../input/analytics-vidhya-jobathon/\")\n    df,cat_features=feature_engineering(df)\n    x_train,y_train,x_test=preparedatafortraining(df,train,test)\n    \n    #x_train.to_pickle(\"x_train_lgbm.pkl\")\n    #y_train.to_pickle(\"y_train_lgbm.pkl\")\n    #x_test.to_pickle(\"x_test_lgbm.pkl\")\n    \n    return x_train,y_train,x_test","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train LGBM Model and save the validation and test set prediction for ensembling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def lgbm_model():\n    \n    x,y,x_test=savedata()\n    \n    params={'lambda': 2.8849054495567423, \n        'alpha': 0.001054193185317787, \n        'colsample_bytree': 0.5, \n        'subsample': 0.4, \n        'learning_rate': 0.014, \n        'max_depth': 13, \n        'random_state': 24,\n        'min_child_weight': 5}\n    \n    err = [] \n\n    oofs = np.zeros(shape=(len(x)))\n    preds = np.zeros(shape=(len(x_test)))\n\n    Folds=8\n\n    fold = StratifiedKFold(n_splits=Folds, shuffle=True, random_state=2020)\n    i = 1\n\n    for train_index, test_index in fold.split(x, y):\n        x_train, x_val = x.iloc[train_index], x.iloc[test_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    \n        m = LGBMClassifier(n_estimators=10000,**params,verbose= -1)\n    \n        m.fit(x_train, y_train,eval_set=[(x_val, y_val)], early_stopping_rounds=30,verbose=False,eval_metric='auc')\n    \n        pred_y = m.predict_proba(x_val)[:,1]\n        oofs[test_index] = pred_y\n        print(i, \" err_lgm: \", roc_auc_score(y_val,pred_y))\n        err.append(roc_auc_score(y_val,pred_y))\n        preds+= m.predict_proba(x_test)[:,1]\n        i = i + 1\n    preds=preds/Folds\n    \n    print(f\"Average StratifiedKFold Score : {sum(err)/Folds} \")\n    oof_score = roc_auc_score(y, oofs)\n    print(f'\\nOOF Auc is : {oof_score}')\n    \n    oofs=pd.DataFrame(oofs,columns=['lgbmoof'])\n    preds=pd.DataFrame(preds,columns=['lgbmpred'])\n    \n    oofs.to_csv('lgbmoof.csv',index=False)\n    preds.to_csv('lgbmpred.csv',index=False)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_model()","execution_count":7,"outputs":[{"output_type":"stream","text":"(48752, 533)\n[LightGBM] [Warning] lambda_l2 is set with lambda=2.8849054495567423, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8849054495567423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n1  err_lgm:  0.8224546903570833\n[LightGBM] [Warning] lambda_l2 is set with lambda=2.8849054495567423, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8849054495567423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n2  err_lgm:  0.8075914491950066\n[LightGBM] [Warning] lambda_l2 is set with lambda=2.8849054495567423, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8849054495567423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n3  err_lgm:  0.8254098613745128\n[LightGBM] [Warning] lambda_l2 is set with lambda=2.8849054495567423, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8849054495567423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n4  err_lgm:  0.8141514620067063\n[LightGBM] [Warning] lambda_l2 is set with lambda=2.8849054495567423, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8849054495567423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n5  err_lgm:  0.8007063365772867\n[LightGBM] [Warning] lambda_l2 is set with lambda=2.8849054495567423, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8849054495567423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n6  err_lgm:  0.8139061610305045\n[LightGBM] [Warning] lambda_l2 is set with lambda=2.8849054495567423, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8849054495567423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n7  err_lgm:  0.8169790418878722\n[LightGBM] [Warning] lambda_l2 is set with lambda=2.8849054495567423, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.8849054495567423\n[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n8  err_lgm:  0.8104893632353531\nAverage StratifiedKFold Score : 0.8139610457080408 \n\nOOF Auc is : 0.8138034878946384\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Train XGB Model and save the validation and test set prediction for ensembling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgb_model():\n    \n    x,y,x_test=savedata()\n    \n    params={'lambda': 1.417495651744778, \n        'alpha': 0.4281901245971981, \n        'colsample_bytree': 0.7, \n        'subsample': 0.8, \n        'learning_rate': 0.016,\n        'max_depth': 9, \n        'random_state': 2020, \n        'min_child_weight': 30}\n    \n    err = [] \n\n    oofs = np.zeros(shape=(len(x)))\n    preds = np.zeros(shape=(len(x_test)))\n\n    Folds=8\n\n    fold = StratifiedKFold(n_splits=Folds, shuffle=True, random_state=2020)\n    i = 1\n\n    for train_index, test_index in fold.split(x, y):\n        x_train, x_val = x.iloc[train_index], x.iloc[test_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    \n        m = XGBClassifier(n_estimators=10000,**params)\n    \n        m.fit(x_train, y_train,eval_set=[(x_val, y_val)], early_stopping_rounds=30,verbose=False,eval_metric='auc')\n    \n        pred_y = m.predict_proba(x_val)[:,1]\n        oofs[test_index] = pred_y\n        print(i, \" err_xgb: \", roc_auc_score(y_val,pred_y))\n        err.append(roc_auc_score(y_val,pred_y))\n        preds+= m.predict_proba(x_test)[:,1]\n        i = i + 1\n    preds=preds/Folds\n    \n    print(f\"Average StratifiedKFold Score : {sum(err)/Folds} \")\n    oof_score = roc_auc_score(y, oofs)\n    print(f'\\nOOF Auc is : {oof_score}')\n    \n    oofs=pd.DataFrame(oofs,columns=['xgboof'])\n    preds=pd.DataFrame(preds,columns=['xgbpred'])\n    \n    oofs.to_csv('xgbmoof.csv',index=False)\n    preds.to_csv('xgbmpred.csv',index=False)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model()","execution_count":9,"outputs":[{"output_type":"stream","text":"(48752, 533)\n1  err_xgb:  0.8222688379779438\n2  err_xgb:  0.8095131302933026\n3  err_xgb:  0.8262987173674321\n4  err_xgb:  0.8158737728461399\n5  err_xgb:  0.8017014659219515\n6  err_xgb:  0.8138619347003774\n7  err_xgb:  0.8185491873577966\n8  err_xgb:  0.8103272246360889\nAverage StratifiedKFold Score : 0.8147992838876292 \n\nOOF Auc is : 0.8145901095374922\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}