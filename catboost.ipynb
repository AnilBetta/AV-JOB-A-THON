{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\npd.set_option('display.max_columns', 100)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom itertools import combinations","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read data and perform basic preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_data(DATA_DIR):\n    \n    train = pd.read_csv(DATA_DIR+\"train_Df64byy.csv\")\n    test = pd.read_csv(DATA_DIR+\"test_YCcRUnU.csv\")\n    \n    #Removes train rows which has Region_Code not present in test set\n    test_region_list=test['Region_Code'].tolist()\n    train=train[train['Region_Code'].isin(test_region_list)]\n    \n    train['train_or_test']='train'\n    test['train_or_test']='test'\n    df=pd.concat([train,test])\n    \n    df['Holding_Policy_Duration']=(df['Holding_Policy_Duration'].replace(['14+'],[15])).astype(float)\n    \n    le = LabelEncoder()\n    for col in ['City_Code','Accomodation_Type','Reco_Insurance_Type','Health Indicator','Is_Spouse']:\n        df[col]=  df[col].astype('str')\n        df[col]= le.fit_transform(df[col])\n        \n\n    \n    return train,test,df","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def frequency_encoding(column_name,output_column_name,df):\n    fe_pol = (df.groupby(column_name).size()) / len(df)\n    df[output_column_name] = df[column_name].apply(lambda x : fe_pol[x])","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def frequency_encoding(column_name,output_column_name,df):\n    fe_pol = (df.groupby(column_name).size()) / len(df)\n    df[output_column_name] = df[column_name].apply(lambda x : fe_pol[x])\n\n\ndef feature_engineering(df):\n    le = LabelEncoder()\n    \n     #Interaction Feature (Combining 2 categorical features and performing frequency encoding)\n        \n    cat_features=[]\n    le_features=[]\n    columns=['City_Code','Accomodation_Type','Reco_Insurance_Type','Health Indicator','Is_Spouse','Region_Code','Holding_Policy_Type','Reco_Policy_Cat']\n\n    comb = combinations(columns, 2) \n\n    for i in list(comb):  \n        df[f'{i[0]}_{i[1]}']=df[i[0]].astype(str)+'_'+df[i[1]].astype(str)\n        df[f'{i[0]}_{i[1]}_le']=le.fit_transform(df[f'{i[0]}_{i[1]}'])\n        le_features.append(f'{i[0]}_{i[1]}_le')\n        frequency_encoding(f'{i[0]}_{i[1]}',f'{i[0]}_{i[1]}',df)\n        cat_features.append(f'{i[0]}_{i[1]}')   \n        \n    #Frequency Encoding\n    \n    frequency_encoding('Region_Code','Region_Code_fe',df)\n    frequency_encoding('Reco_Policy_Cat','Reco_Policy_Cat_fe',df)\n    \n    #Deriving characteristics of each city by creating aggregate features\n    \n    city_aggregate_features = df.groupby(['City_Code']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'Holding_Policy_Type': ['nunique','count'] ,\n                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n                                                     })\n    city_aggregate_features.columns = ['city_aggregate_features' + '_'.join(c).strip('_') for c in city_aggregate_features.columns]\n    df = pd.merge(df, city_aggregate_features, on = ['City_Code'], how='left')\n\n \n    city_region_aggregate_features = df.groupby(['City_Code','Region_Code']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'],  \n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'Holding_Policy_Type': ['nunique','count'] ,\n                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n                                                     })\n    city_region_aggregate_features.columns = ['city_region_aggregate_features' + '_'.join(c).strip('_') for c in city_region_aggregate_features.columns]\n    df = pd.merge(df, city_region_aggregate_features, on = ['City_Code','Region_Code'], how='left')\n\n    city_recopolicycat_aggregate_features = df.groupby(['City_Code','Reco_Policy_Cat']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'Holding_Policy_Type': ['nunique','count'] \n                                                     })\n    city_recopolicycat_aggregate_features.columns = ['city_recopolicycat_aggregate_features' + '_'.join(c).strip('_') for c in city_recopolicycat_aggregate_features.columns]\n    df = pd.merge(df, city_recopolicycat_aggregate_features, on = ['City_Code','Reco_Policy_Cat'], how='left')\n    \n    city_regioncoderecopolicycat_aggregate_features = df.groupby(['City_Code','Region_Code_Reco_Policy_Cat']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'Holding_Policy_Type': ['nunique','count'] ,\n                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n                                                     })\n\n    city_regioncoderecopolicycat_aggregate_features.columns = ['city_regioncoderecopolicycat_aggregate_features' + '_'.join(c).strip('_') for c in city_regioncoderecopolicycat_aggregate_features.columns]\n    df = pd.merge(df, city_regioncoderecopolicycat_aggregate_features, on = ['City_Code','Region_Code_Reco_Policy_Cat'], how='left')\n    \n    for i in cat_features:\n        df[f'city_{i}_max']=df.groupby('City_Code')[i].transform('max')\n        df[f'city_{i}_min']=df.groupby('City_Code')[i].transform('min')\n        df[f'city_{i}_mean']=df.groupby('City_Code')[i].transform('mean')\n        df[f'city_{i}_std']=df.groupby('City_Code')[i].transform('std')\n\n    \n        df[f'city_region_{i}_max']=df.groupby(['City_Code','Region_Code'])[i].transform('max')\n        df[f'city_region_{i}_min']=df.groupby(['City_Code','Region_Code'])[i].transform('min')\n        df[f'city_region_{i}_mean']=df.groupby(['City_Code','Region_Code'])[i].transform('mean')\n        df[f'city_region_{i}_std']=df.groupby(['City_Code','Region_Code'])[i].transform('std')\n\n    \n        df[f'city_recopolicycat_{i}_max']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('max')\n        df[f'city_recopolicycat_{i}_min']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('min')\n        df[f'city_recopolicycat_{i}_mean']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('mean')\n        df[f'city_recopolicycat_{i}_std']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('std')\n        \n    \n    #features on reco_policy_cat\n    \n    recopolicycat_aggregate_features = df.groupby(['Reco_Policy_Cat']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'],   \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Accomodation_Type': ['nunique'],\n                                                     'Reco_Insurance_Type': ['nunique'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'Holding_Policy_Type': ['nunique','count'] ,\n                                                     'City_Code': ['nunique','count'] ,\n                                                     })\n    recopolicycat_aggregate_features.columns = ['recopolicycat_aggregate_features' + '_'.join(c).strip('_') for c in recopolicycat_aggregate_features.columns]\n    df = pd.merge(df, recopolicycat_aggregate_features, on = ['Reco_Policy_Cat'], how='left')\n        \n        \n\n    #features on Holding_Policy_Type \n    \n    holdingpolicytype_aggregate_features = df.groupby(['Holding_Policy_Type']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Accomodation_Type': ['nunique','count'],\n                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'City_Code': ['nunique','count'] ,\n                                                     })\n    holdingpolicytype_aggregate_features.columns = ['holdingpolicytype_aggregate_features' + '_'.join(c).strip('_') for c in holdingpolicytype_aggregate_features.columns]\n    df = pd.merge(df, holdingpolicytype_aggregate_features, on = ['Holding_Policy_Type'], how='left')\n    \n    #Deriving characteristics of Accomodation_Type by creating aggregate features\n    \n    Accomodation_Type_aggregate_features = df.groupby(['Accomodation_Type']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'],   \n                                                     'Region_Code': ['nunique','count'], \n                                                     'Reco_Insurance_Type': ['nunique'] ,\n                                                     'Health Indicator': ['nunique','count'] ,\n                                                     'Holding_Policy_Type': ['nunique','count'] ,\n                                                     'City_Code': ['nunique','count'] ,\n                                                     })\n    Accomodation_Type_aggregate_features.columns = ['Accomodation_Type_aggregate_features' + '_'.join(c).strip('_') for c in Accomodation_Type_aggregate_features.columns]\n    df = pd.merge(df, Accomodation_Type_aggregate_features, on = ['Accomodation_Type'], how='left')\n    \n    #Deriving characteristics of Interaction_features by creating aggregate features (These interaction feature are selected for aggregating based on its feature importance)\n    \n    Region_CodeReco_Policy_Cat_grpd = df.groupby(['Region_Code_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n                                                     \n    Region_CodeReco_Policy_Cat_grpd.columns = ['grpd_by_Region_Code_Reco_Policy_Cat_' + '_'.join(c).strip('_') for c in Region_CodeReco_Policy_Cat_grpd.columns]\n    df = pd.merge(df, Region_CodeReco_Policy_Cat_grpd, on = ['Region_Code_Reco_Policy_Cat'], how='left')\n\n\n    City_CodeRegion_Code_grpd = df.groupby(['City_Code_Region_Code']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n                                                     \n    City_CodeRegion_Code_grpd.columns = ['grpd_by_City_CodeRegion_Code_' + '_'.join(c).strip('_') for c in City_CodeRegion_Code_grpd.columns]\n    df = pd.merge(df, City_CodeRegion_Code_grpd, on = ['City_Code_Region_Code'], how='left')\n\n\n    City_CodeReco_Policy_Cat_grpd = df.groupby(['City_Code_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n                                                     \n    City_CodeReco_Policy_Cat_grpd.columns = ['grpd_by_City_CodeReco_Policy_Cat_' + '_'.join(c).strip('_') for c in City_CodeReco_Policy_Cat_grpd.columns]\n    df = pd.merge(df, City_CodeReco_Policy_Cat_grpd, on = ['City_Code_Reco_Policy_Cat'], how='left')\n\n\n    Holding_Policy_TypeReco_Policy_Cat_grpd = df.groupby(['Holding_Policy_Type_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n                                                     \n    Holding_Policy_TypeReco_Policy_Cat_grpd.columns = ['grpd_by_Holding_Policy_TypeReco_Policy_Cat_' + '_'.join(c).strip('_') for c in Holding_Policy_TypeReco_Policy_Cat_grpd.columns]\n    df = pd.merge(df, Holding_Policy_TypeReco_Policy_Cat_grpd, on = ['Holding_Policy_Type_Reco_Policy_Cat'], how='left')\n    \n    return df,le_features\n    ","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove unnecessary columns and prepare the train and test data for training"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preparedatafortraining(df,train,test):\n    \n    train=df.loc[df.train_or_test.isin(['train'])]\n    test=df.loc[df.train_or_test.isin(['test'])]\n    \n    drop_columns={'ID','Response','Upper_Age','train_or_test'}\n    \n    target=['Response']\n    \n    x=train.drop(columns=drop_columns,axis=1)\n    y=train[target]\n    x_test=test.drop(columns=drop_columns,axis=1)\n    \n    print(x.shape)\n    \n    return x,y,x_test","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Save Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def savedata(**DATA_DIR):\n    \n    train,test,df=process_data(\"../input/analytics-vidhya-jobathon/\")\n    df,cat_features=feature_engineering(df)\n    x_train,y_train,x_test=preparedatafortraining(df,train,test)\n    \n    #x_train.to_pickle(\"x_train_lgbm.pkl\")\n    #y_train.to_pickle(\"y_train_lgbm.pkl\")\n    #x_test.to_pickle(\"x_test_lgbm.pkl\")\n    \n    return x_train,y_train,x_test,cat_features","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train CatBoost Model and save the validation and test set prediction for ensembling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def catboost_model():\n    \n    x,y,x_test,cat_features=savedata()\n     \n    err = [] \n\n    oofs = np.zeros(shape=(len(x)))\n    preds = np.zeros(shape=(len(x_test)))\n\n    Folds=8\n\n    fold = StratifiedKFold(n_splits=Folds, shuffle=True, random_state=2020)\n    i = 1\n\n    for train_index, test_index in fold.split(x, y):\n        x_train, x_val = x.iloc[train_index], x.iloc[test_index]\n        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    \n        m =  CatBoostClassifier(n_estimators=10000,random_state=2020,eval_metric='AUC')\n    \n        m.fit(x_train, y_train,eval_set=[(x_val, y_val)], early_stopping_rounds=30,verbose=100,cat_features=cat_features)\n    \n        pred_y = m.predict_proba(x_val)[:,1]\n        oofs[test_index] = pred_y\n        print(i, \" err_cat: \", roc_auc_score(y_val,pred_y))\n        err.append(roc_auc_score(y_val,pred_y))\n        preds+= m.predict_proba(x_test)[:,1]\n        i = i + 1\n    preds=preds/Folds\n    \n    print(f\"Average StratifiedKFold Score : {sum(err)/Folds} \")\n    oof_score = roc_auc_score(y, oofs)\n    print(f'\\nOOF Auc is : {oof_score}')\n    \n    oofs=pd.DataFrame(oofs,columns=['catboostoof'])\n    preds=pd.DataFrame(preds,columns=['catboostpred'])\n    \n    oofs.to_csv('catboostoof.csv',index=False)\n    preds.to_csv('catboostpred.csv',index=False)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catboost_model()","execution_count":8,"outputs":[{"output_type":"stream","text":"(48752, 552)\nLearning rate set to 0.029412\n0:\ttest: 0.7636705\tbest: 0.7636705 (0)\ttotal: 336ms\tremaining: 55m 56s\n100:\ttest: 0.8133179\tbest: 0.8133179 (100)\ttotal: 25.7s\tremaining: 42m 1s\n200:\ttest: 0.8176711\tbest: 0.8176711 (200)\ttotal: 50.5s\tremaining: 41m 4s\n300:\ttest: 0.8191514\tbest: 0.8191629 (299)\ttotal: 1m 14s\tremaining: 40m 14s\n400:\ttest: 0.8204221\tbest: 0.8204221 (400)\ttotal: 1m 39s\tremaining: 39m 34s\n500:\ttest: 0.8214007\tbest: 0.8214007 (500)\ttotal: 2m 2s\tremaining: 38m 49s\n600:\ttest: 0.8223918\tbest: 0.8224123 (597)\ttotal: 2m 27s\tremaining: 38m 21s\n700:\ttest: 0.8231721\tbest: 0.8231721 (700)\ttotal: 2m 51s\tremaining: 37m 49s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.823356621\nbestIteration = 719\n\nShrink model to first 720 iterations.\n1  err_cat:  0.8233566210205541\nLearning rate set to 0.029412\n0:\ttest: 0.7472616\tbest: 0.7472616 (0)\ttotal: 274ms\tremaining: 45m 36s\n100:\ttest: 0.7987846\tbest: 0.7987846 (100)\ttotal: 25.6s\tremaining: 41m 52s\n200:\ttest: 0.8041365\tbest: 0.8041532 (199)\ttotal: 50.6s\tremaining: 41m 4s\n300:\ttest: 0.8061496\tbest: 0.8061496 (300)\ttotal: 1m 15s\tremaining: 40m 39s\n400:\ttest: 0.8075186\tbest: 0.8075619 (396)\ttotal: 1m 39s\tremaining: 39m 45s\n500:\ttest: 0.8083763\tbest: 0.8083763 (500)\ttotal: 2m 3s\tremaining: 39m 6s\n600:\ttest: 0.8090213\tbest: 0.8090506 (592)\ttotal: 2m 27s\tremaining: 38m 25s\n700:\ttest: 0.8094298\tbest: 0.8094531 (696)\ttotal: 2m 51s\tremaining: 37m 54s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.8095717816\nbestIteration = 730\n\nShrink model to first 731 iterations.\n2  err_cat:  0.8095717816402965\nLearning rate set to 0.029412\n0:\ttest: 0.7674204\tbest: 0.7674204 (0)\ttotal: 290ms\tremaining: 48m 20s\n100:\ttest: 0.8193290\tbest: 0.8193290 (100)\ttotal: 26.1s\tremaining: 42m 41s\n200:\ttest: 0.8238929\tbest: 0.8238929 (200)\ttotal: 51.1s\tremaining: 41m 31s\n300:\ttest: 0.8255686\tbest: 0.8255995 (295)\ttotal: 1m 15s\tremaining: 40m 43s\n400:\ttest: 0.8267162\tbest: 0.8267162 (400)\ttotal: 1m 39s\tremaining: 39m 50s\n500:\ttest: 0.8273919\tbest: 0.8273978 (499)\ttotal: 2m 3s\tremaining: 39m 8s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.8275902289\nbestIteration = 547\n\nShrink model to first 548 iterations.\n3  err_cat:  0.8275902288924218\nLearning rate set to 0.029412\n0:\ttest: 0.7490986\tbest: 0.7490986 (0)\ttotal: 271ms\tremaining: 45m 14s\n100:\ttest: 0.8061060\tbest: 0.8061060 (100)\ttotal: 25.8s\tremaining: 42m 12s\n200:\ttest: 0.8109615\tbest: 0.8109615 (200)\ttotal: 50.3s\tremaining: 40m 51s\n300:\ttest: 0.8131443\tbest: 0.8131508 (299)\ttotal: 1m 14s\tremaining: 40m 1s\n400:\ttest: 0.8143200\tbest: 0.8143200 (400)\ttotal: 1m 38s\tremaining: 39m 21s\n500:\ttest: 0.8151482\tbest: 0.8152005 (498)\ttotal: 2m 2s\tremaining: 38m 49s\n600:\ttest: 0.8155098\tbest: 0.8155722 (590)\ttotal: 2m 26s\tremaining: 38m 12s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.8155937385\nbestIteration = 613\n\nShrink model to first 614 iterations.\n4  err_cat:  0.8155937385181125\nLearning rate set to 0.029412\n0:\ttest: 0.7421195\tbest: 0.7421195 (0)\ttotal: 266ms\tremaining: 44m 16s\n100:\ttest: 0.7928726\tbest: 0.7928726 (100)\ttotal: 25.9s\tremaining: 42m 22s\n200:\ttest: 0.7969229\tbest: 0.7969753 (199)\ttotal: 50.5s\tremaining: 41m 3s\n300:\ttest: 0.7988814\tbest: 0.7988814 (300)\ttotal: 1m 14s\tremaining: 40m 6s\n400:\ttest: 0.7999655\tbest: 0.7999808 (398)\ttotal: 1m 39s\tremaining: 39m 31s\n500:\ttest: 0.8009388\tbest: 0.8010527 (492)\ttotal: 2m 3s\tremaining: 38m 57s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.8011298461\nbestIteration = 522\n\nShrink model to first 523 iterations.\n5  err_cat:  0.8011298461425779\nLearning rate set to 0.029412\n0:\ttest: 0.7544542\tbest: 0.7544542 (0)\ttotal: 282ms\tremaining: 46m 55s\n100:\ttest: 0.8035522\tbest: 0.8035522 (100)\ttotal: 26s\tremaining: 42m 24s\n200:\ttest: 0.8074119\tbest: 0.8074248 (197)\ttotal: 50.7s\tremaining: 41m 12s\n300:\ttest: 0.8094657\tbest: 0.8094657 (300)\ttotal: 1m 15s\tremaining: 40m 18s\n400:\ttest: 0.8104356\tbest: 0.8104452 (398)\ttotal: 1m 39s\tremaining: 39m 34s\n500:\ttest: 0.8112730\tbest: 0.8113868 (481)\ttotal: 2m 3s\tremaining: 39m 2s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.8113868107\nbestIteration = 481\n\nShrink model to first 482 iterations.\n6  err_cat:  0.8113868107189858\nLearning rate set to 0.029412\n0:\ttest: 0.7506176\tbest: 0.7506176 (0)\ttotal: 261ms\tremaining: 43m 31s\n100:\ttest: 0.8087582\tbest: 0.8087582 (100)\ttotal: 25.8s\tremaining: 42m 6s\n200:\ttest: 0.8139664\tbest: 0.8139664 (200)\ttotal: 50.8s\tremaining: 41m 16s\n300:\ttest: 0.8155476\tbest: 0.8155476 (300)\ttotal: 1m 14s\tremaining: 40m 11s\n400:\ttest: 0.8167622\tbest: 0.8167671 (397)\ttotal: 1m 38s\tremaining: 39m 28s\n500:\ttest: 0.8175787\tbest: 0.8176114 (499)\ttotal: 2m 3s\tremaining: 38m 56s\n600:\ttest: 0.8182094\tbest: 0.8182345 (596)\ttotal: 2m 27s\tremaining: 38m 20s\n700:\ttest: 0.8187951\tbest: 0.8187999 (699)\ttotal: 2m 50s\tremaining: 37m 43s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.8188108537\nbestIteration = 705\n\nShrink model to first 706 iterations.\n7  err_cat:  0.8188108536582483\nLearning rate set to 0.029412\n0:\ttest: 0.7612739\tbest: 0.7612739 (0)\ttotal: 277ms\tremaining: 46m 10s\n100:\ttest: 0.8046505\tbest: 0.8046505 (100)\ttotal: 25.8s\tremaining: 42m 11s\n200:\ttest: 0.8092233\tbest: 0.8092233 (200)\ttotal: 50.9s\tremaining: 41m 20s\n300:\ttest: 0.8112138\tbest: 0.8112138 (300)\ttotal: 1m 15s\tremaining: 40m 23s\n400:\ttest: 0.8125318\tbest: 0.8125318 (400)\ttotal: 1m 39s\tremaining: 39m 36s\n500:\ttest: 0.8134118\tbest: 0.8134118 (500)\ttotal: 2m 2s\tremaining: 38m 49s\nStopped by overfitting detector  (30 iterations wait)\n\nbestTest = 0.8135413492\nbestIteration = 529\n\nShrink model to first 530 iterations.\n8  err_cat:  0.8135413491821599\nAverage StratifiedKFold Score : 0.8151226537216696 \n\nOOF Auc is : 0.8150003835630804\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}